{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b594d86c-f9c1-4560-a016-4890b94dbfd1",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "b594d86c-f9c1-4560-a016-4890b94dbfd1"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0a61b90-9318-495e-a055-6450e45c2239",
      "metadata": {
        "id": "c0a61b90-9318-495e-a055-6450e45c2239",
        "outputId": "bac96c32-26c9-41c1-9722-4af0b24f258a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "INFO: pip is looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torch\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torch-2.7.0%2Bcu118-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (28 kB)\n",
            "Collecting sympy>=1.13.3 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.8.89 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (23.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.8.89 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (875 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m875.6/875.6 kB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.8.87 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux1_x86_64.whl (13.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==9.1.0.70 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cudnn_cu11-9.1.0.70-py3-none-manylinux2014_x86_64.whl (663.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m663.9/663.9 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.11.3.6 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux1_x86_64.whl (417.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.3.0.86 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_curand_cu11-10.3.0.86-py3-none-manylinux1_x86_64.whl (58.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.1.48 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux1_x86_64.whl (128.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.5.86 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux1_x86_64.whl (204.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.1/204.1 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.21.5 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nccl_cu11-2.21.5-py3-none-manylinux2014_x86_64.whl (147.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.8.86 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nvtx_cu11-11.8.86-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==3.3.0 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.0->torch) (75.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Collecting torch\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torch-2.6.0%2Bcu118-cp311-cp311-linux_x86_64.whl.metadata (27 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading https://download.pytorch.org/whl/cu118/torch-2.6.0%2Bcu118-cp311-cp311-linux_x86_64.whl (848.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m848.7/848.7 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "Successfully installed nvidia-cublas-cu11-11.11.3.6 nvidia-cuda-cupti-cu11-11.8.87 nvidia-cuda-nvrtc-cu11-11.8.89 nvidia-cuda-runtime-cu11-11.8.89 nvidia-cudnn-cu11-9.1.0.70 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.3.0.86 nvidia-cusolver-cu11-11.4.1.48 nvidia-cusparse-cu11-11.7.5.86 nvidia-nccl-cu11-2.21.5 nvidia-nvtx-cu11-11.8.86 torch-2.6.0+cu118\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch",
                  "torchgen"
                ]
              },
              "id": "6593addd76ed4909b15b3e117a7ac1d2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "# imports\n",
        "\n",
        "!pip install pandas\n",
        "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install nltk\n",
        "!pip install -U datasets\n",
        "!pip install torchtext\n",
        "\n",
        "import string\n",
        "import torch\n",
        "import pandas as pd\n",
        "import datasets\n",
        "from datasets import Dataset\n",
        "import torchtext\n",
        "from torchtext.vocab import Vocab, build_vocab_from_iterator\n",
        "from collections import Counter\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10f755cf-8361-4f02-a559-3890565dd43a",
      "metadata": {
        "id": "10f755cf-8361-4f02-a559-3890565dd43a"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "308ad95c-3b68-4f6c-a4bf-005c1c07edab",
      "metadata": {
        "id": "308ad95c-3b68-4f6c-a4bf-005c1c07edab",
        "outputId": "d804f355-7778-4c1e-db40-d50a1027a1ee"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>zu</th>\n",
              "      <th>en</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Lomkhakha kufanele uthuthukiswe, lawa amazwi k...</td>\n",
              "      <td>This sector needs to be developed,  These are ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Yonke imibuzo: Ucingo: 031- 311 3154 (Shaks Ra...</td>\n",
              "      <td>All questions: Phone: 031- 311 3154 (Shaks Ram...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Axhumanisa umphakathi noMkhandlu ngoba abika k...</td>\n",
              "      <td>They connect the community with the Council be...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  zu  \\\n",
              "0  Lomkhakha kufanele uthuthukiswe, lawa amazwi k...   \n",
              "1  Yonke imibuzo: Ucingo: 031- 311 3154 (Shaks Ra...   \n",
              "2  Axhumanisa umphakathi noMkhandlu ngoba abika k...   \n",
              "\n",
              "                                                  en  \n",
              "0  This sector needs to be developed,  These are ...  \n",
              "1  All questions: Phone: 031- 311 3154 (Shaks Ram...  \n",
              "2  They connect the community with the Council be...  "
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# load training dataset\n",
        "train_df = pd.read_csv(r\"../Dataset/zu-en.training.csv\")\n",
        "train_df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f988f661-4c83-445e-a150-d089c50ed285",
      "metadata": {
        "id": "f988f661-4c83-445e-a150-d089c50ed285",
        "outputId": "8272838f-e3de-45fa-e868-f9b6fbd8a0af"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>zu</th>\n",
              "      <th>en</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ikomidi elihlelela imidlalo ye-2013 Orange Afr...</td>\n",
              "      <td>The 2013 Orange Africa Cup of Nations (known a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Futhi ipolitiki akuwona umdlalo wabantu abanga...</td>\n",
              "      <td>And politics is not a game for  immature people.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ikhasi lethu lakwa e-Careers likubeka ngokucac...</td>\n",
              "      <td>Our e-Careers page makes it clear that if you ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  zu  \\\n",
              "0  Ikomidi elihlelela imidlalo ye-2013 Orange Afr...   \n",
              "1  Futhi ipolitiki akuwona umdlalo wabantu abanga...   \n",
              "2  Ikhasi lethu lakwa e-Careers likubeka ngokucac...   \n",
              "\n",
              "                                                  en  \n",
              "0  The 2013 Orange Africa Cup of Nations (known a...  \n",
              "1   And politics is not a game for  immature people.  \n",
              "2  Our e-Careers page makes it clear that if you ...  "
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# load evaluation dataset\n",
        "eval_df = pd.read_csv(r\"../Dataset/zu-en.eval.csv\")\n",
        "eval_df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9219e94-4c0e-47e9-a0b9-78e1219191ec",
      "metadata": {
        "id": "e9219e94-4c0e-47e9-a0b9-78e1219191ec",
        "outputId": "5317c90d-ebd3-4420-e944-235c9ba70bd2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>zu</th>\n",
              "      <th>en</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NONDUDUZO NGCONGO SEKUVELILE ukuthi ezokuvakas...</td>\n",
              "      <td>NONDUDUZO NGCONGO It has come to light that to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Umkhankaso uzobe usezindaweni zokubhukuda ezis...</td>\n",
              "      <td>The campaign will be at the swimming pools in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SinguMasipala siyakuqonda ukukhala kwabantu ka...</td>\n",
              "      <td>As a Municipality we understand the cries of t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  zu  \\\n",
              "0  NONDUDUZO NGCONGO SEKUVELILE ukuthi ezokuvakas...   \n",
              "1  Umkhankaso uzobe usezindaweni zokubhukuda ezis...   \n",
              "2  SinguMasipala siyakuqonda ukukhala kwabantu ka...   \n",
              "\n",
              "                                                  en  \n",
              "0  NONDUDUZO NGCONGO It has come to light that to...  \n",
              "1  The campaign will be at the swimming pools in ...  \n",
              "2  As a Municipality we understand the cries of t...  "
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# load test dataset\n",
        "test_df = pd.read_csv(r\"../Dataset/zu-en.test.csv\")\n",
        "test_df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "112e5d2b-00ec-4a07-b5fe-a34bec762572",
      "metadata": {
        "id": "112e5d2b-00ec-4a07-b5fe-a34bec762572",
        "outputId": "1487fbf3-e669-4191-d546-e9857066d035"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'zu': Value(dtype='string', id=None), 'en': Value(dtype='string', id=None)}\n",
            "{'zu': Value(dtype='string', id=None), 'en': Value(dtype='string', id=None)}\n",
            "{'zu': Value(dtype='string', id=None), 'en': Value(dtype='string', id=None)}\n"
          ]
        }
      ],
      "source": [
        "# convert panda dataframes to HuggingFace datasets for easy data manipulation\n",
        "train_data = Dataset.from_pandas(train_df)\n",
        "eval_data = Dataset.from_pandas(eval_df)\n",
        "test_data = Dataset.from_pandas(test_df)\n",
        "\n",
        "# show features to work with\n",
        "print(f\"{train_data.features}\\n{eval_data.features}\\n{test_data.features}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f9359df-3d56-4191-88eb-fe38eaea998a",
      "metadata": {
        "id": "1f9359df-3d56-4191-88eb-fe38eaea998a"
      },
      "outputs": [],
      "source": [
        "# function to tokenize a row (example) in dataset using .map function\n",
        "def tokenize_example(example, max_length, lower, sos_token, eos_token):\n",
        "    zu_tokens = word_tokenize(example[\"zu\"])[:max_length]\n",
        "    en_tokens = word_tokenize(example[\"en\"])[:max_length]\n",
        "    if lower:\n",
        "        zu_tokens = [token.lower() for token in zu_tokens]\n",
        "        en_tokens = [token.lower() for token in en_tokens]\n",
        "    zu_tokens = [sos_token] + zu_tokens + [eos_token]\n",
        "    en_tokens = [sos_token] + en_tokens + [eos_token]\n",
        "    return {\"zu_tokens\": zu_tokens, \"en_tokens\": en_tokens}\n",
        "\n",
        "\n",
        "# maybe try with spacy (treating zulu as english and tokenize both with en_nlp?)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2308110a-30fa-421e-b415-23d3e24d9766",
      "metadata": {
        "id": "2308110a-30fa-421e-b415-23d3e24d9766",
        "outputId": "8c64b234-d813-4b33-bde5-69f0e1e8aa7c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|████████████████████████████████████████████████████████████████| 4960/4960 [00:01<00:00, 4141.05 examples/s]\n",
            "Map: 100%|██████████████████████████████████████████████████████████████████| 498/498 [00:00<00:00, 3761.39 examples/s]\n",
            "Map: 100%|██████████████████████████████████████████████████████████████████| 487/487 [00:00<00:00, 3986.90 examples/s]\n"
          ]
        }
      ],
      "source": [
        "max_length = 500\n",
        "lower = True\n",
        "sos_token = \"<sos>\"\n",
        "eos_token = \"<eos>\"\n",
        "\n",
        "fn_kwargs = {\n",
        "    \"max_length\": max_length,\n",
        "    \"lower\": lower,\n",
        "    \"sos_token\": sos_token,\n",
        "    \"eos_token\": eos_token,\n",
        "}\n",
        "\n",
        "train_data = train_data.map(tokenize_example, fn_kwargs=fn_kwargs)\n",
        "eval_data = eval_data.map(tokenize_example, fn_kwargs=fn_kwargs)\n",
        "test_data = test_data.map(tokenize_example, fn_kwargs=fn_kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5013862d-635a-4d6d-a77c-3064ab0dd6da",
      "metadata": {
        "id": "5013862d-635a-4d6d-a77c-3064ab0dd6da",
        "outputId": "15f4d899-e610-41d5-84fe-601f7cca81f7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "4960lines [00:00, 259712.47lines/s]\n",
            "4960lines [00:00, 206130.77lines/s]\n"
          ]
        }
      ],
      "source": [
        "# build vocabulary\n",
        "min_freq = 1    # maybe change to 2\n",
        "zu_counter = Counter()\n",
        "en_counter = Counter()\n",
        "\n",
        "for tokens in train_data[\"zu_tokens\"]:\n",
        "    zu_counter.update(tokens)\n",
        "\n",
        "for tokens in train_data[\"en_tokens\"]:\n",
        "    en_counter.update(tokens)\n",
        "\n",
        "zu_vocab = build_vocab_from_iterator(\n",
        "    train_data[\"zu_tokens\"],\n",
        ")\n",
        "\n",
        "en_vocab = build_vocab_from_iterator(\n",
        "    train_data[\"en_tokens\"],\n",
        ")\n",
        "\n",
        "# apply min_freq\n",
        "zu_vocab = Vocab(zu_counter, min_freq=min_freq)\n",
        "en_vocab = Vocab(en_counter, min_freq=min_freq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62e0face-b79f-468f-8260-a538e6bf2a90",
      "metadata": {
        "id": "62e0face-b79f-468f-8260-a538e6bf2a90",
        "outputId": "b78886f3-0b36-4bd2-c62d-96757e1603c7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['<unk>', '<pad>', '.', '<eos>', '<sos>', ',', 'ukuthi', ':', '(', ')']"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# show items in vocab, torchtext adds unk and pad tokens\n",
        "# unk is for words in eval and test but not in train\n",
        "zu_vocab.itos[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfcf2b0b-fb71-4a52-b268-48190d2ff6f8",
      "metadata": {
        "id": "bfcf2b0b-fb71-4a52-b268-48190d2ff6f8"
      },
      "outputs": [],
      "source": [
        "# function to convert tokens in vocab to indices\n",
        "def numericalize_example(example, zu_vocab , en_vocab):\n",
        "    zu_ids = [zu_vocab.stoi[token] for token in example[\"zu_tokens\"]]\n",
        "    en_ids = [en_vocab.stoi[token] for token in example[\"en_tokens\"]]\n",
        "    return {\"zu_ids\": zu_ids, \"en_ids\": en_ids}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0443941-4229-4a97-a478-5beae5c8732f",
      "metadata": {
        "id": "e0443941-4229-4a97-a478-5beae5c8732f",
        "outputId": "e5b7d16d-2d52-4274-ec2b-60c7a373e423"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|████████████████████████████████████████████████████████████████| 4960/4960 [00:00<00:00, 6394.89 examples/s]\n",
            "Map: 100%|██████████████████████████████████████████████████████████████████| 498/498 [00:00<00:00, 5725.98 examples/s]\n",
            "Map: 100%|██████████████████████████████████████████████████████████████████| 487/487 [00:00<00:00, 6191.18 examples/s]\n"
          ]
        }
      ],
      "source": [
        "# use .map function to iteratively use the numericalize_example function\n",
        "fn_kwargs = {\"zu_vocab\": zu_vocab, \"en_vocab\": en_vocab}\n",
        "\n",
        "train_data = train_data.map(numericalize_example, fn_kwargs=fn_kwargs)\n",
        "eval_data = eval_data.map(numericalize_example, fn_kwargs=fn_kwargs)\n",
        "test_data = test_data.map(numericalize_example, fn_kwargs=fn_kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bb1d324-6b62-430c-811b-f5dd7ba0a259",
      "metadata": {
        "id": "0bb1d324-6b62-430c-811b-f5dd7ba0a259",
        "outputId": "b9e9e8bf-82ac-40c3-ea0b-210bc5fc5a8b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'zu': 'Lomkhakha kufanele uthuthukiswe, lawa amazwi kaSomlomo, uLogie Naidoo ekhuluma kwinkomfa nombukiso wobuciko ebuse Durban ICC ngesonto elidlule.',\n",
              " 'en': 'This sector needs to be developed,  These are the words of Speaker, Logie Naidoo, from a conference and art exhibition held at the Durban ICC last week.',\n",
              " 'zu_tokens': ['<sos>',\n",
              "  'lomkhakha',\n",
              "  'kufanele',\n",
              "  'uthuthukiswe',\n",
              "  ',',\n",
              "  'lawa',\n",
              "  'amazwi',\n",
              "  'kasomlomo',\n",
              "  ',',\n",
              "  'ulogie',\n",
              "  'naidoo',\n",
              "  'ekhuluma',\n",
              "  'kwinkomfa',\n",
              "  'nombukiso',\n",
              "  'wobuciko',\n",
              "  'ebuse',\n",
              "  'durban',\n",
              "  'icc',\n",
              "  'ngesonto',\n",
              "  'elidlule',\n",
              "  '.',\n",
              "  '<eos>'],\n",
              " 'en_tokens': ['<sos>',\n",
              "  'this',\n",
              "  'sector',\n",
              "  'needs',\n",
              "  'to',\n",
              "  'be',\n",
              "  'developed',\n",
              "  ',',\n",
              "  'these',\n",
              "  'are',\n",
              "  'the',\n",
              "  'words',\n",
              "  'of',\n",
              "  'speaker',\n",
              "  ',',\n",
              "  'logie',\n",
              "  'naidoo',\n",
              "  ',',\n",
              "  'from',\n",
              "  'a',\n",
              "  'conference',\n",
              "  'and',\n",
              "  'art',\n",
              "  'exhibition',\n",
              "  'held',\n",
              "  'at',\n",
              "  'the',\n",
              "  'durban',\n",
              "  'icc',\n",
              "  'last',\n",
              "  'week',\n",
              "  '.',\n",
              "  '<eos>'],\n",
              " 'zu_ids': [4,\n",
              "  5501,\n",
              "  43,\n",
              "  20930,\n",
              "  5,\n",
              "  1898,\n",
              "  2178,\n",
              "  5114,\n",
              "  5,\n",
              "  2064,\n",
              "  812,\n",
              "  469,\n",
              "  14252,\n",
              "  5926,\n",
              "  21606,\n",
              "  9891,\n",
              "  97,\n",
              "  1113,\n",
              "  484,\n",
              "  4581,\n",
              "  2,\n",
              "  3],\n",
              " 'en_ids': [5,\n",
              "  14,\n",
              "  340,\n",
              "  256,\n",
              "  6,\n",
              "  16,\n",
              "  835,\n",
              "  7,\n",
              "  46,\n",
              "  18,\n",
              "  2,\n",
              "  1421,\n",
              "  8,\n",
              "  736,\n",
              "  7,\n",
              "  1503,\n",
              "  769,\n",
              "  7,\n",
              "  36,\n",
              "  12,\n",
              "  192,\n",
              "  9,\n",
              "  1315,\n",
              "  381,\n",
              "  105,\n",
              "  21,\n",
              "  2,\n",
              "  39,\n",
              "  975,\n",
              "  167,\n",
              "  396,\n",
              "  3,\n",
              "  4]}"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# show new features in an example (zu_ids and en_ids)\n",
        "train_data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5852138f-ce21-45bc-99c9-ad7346e295ea",
      "metadata": {
        "id": "5852138f-ce21-45bc-99c9-ad7346e295ea",
        "outputId": "c3f2ed83-7895-45bf-d8e3-e5bb730f4ef4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# convert indices to PyTorch tensors for use with PyTorch\n",
        "data_type = \"torch\"\n",
        "format_columns = [\"zu_ids\", \"en_ids\"]\n",
        "\n",
        "train_data = train_data.with_format(\n",
        "    type=data_type,\n",
        "    columns=format_columns,\n",
        "    output_all_columns=True,\n",
        ")\n",
        "\n",
        "eval_data = eval_data.with_format(\n",
        "    type=data_type,\n",
        "    columns=format_columns,\n",
        "    output_all_columns=True,\n",
        ")\n",
        "\n",
        "test_data = test_data.with_format(\n",
        "    type=data_type,\n",
        "    columns=format_columns,\n",
        "    output_all_columns=True,\n",
        ")\n",
        "\n",
        "# show new type of indices\n",
        "type(train_data[0][\"en_ids\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55f1f193-0b44-426b-a341-22717b746d07",
      "metadata": {
        "id": "55f1f193-0b44-426b-a341-22717b746d07"
      },
      "outputs": [],
      "source": [
        "# function for padding our examples and getting 'batches'\n",
        "# batches - set of examples\n",
        "# padding_index = 1 by default.\n",
        "def get_collate_fn():\n",
        "    def collate_fn(batch):\n",
        "        batch_zu_ids = [example[\"zu_ids\"] for example in batch]\n",
        "        batch_en_ids = [example[\"en_ids\"] for example in batch]\n",
        "        batch_zu_ids = nn.utils.rnn.pad_sequence(batch_zu_ids, padding_value=1)\n",
        "        batch_en_ids = nn.utils.rnn.pad_sequence(batch_en_ids, padding_value=1)\n",
        "        batch = {\n",
        "            \"zu_ids\": batch_zu_ids,\n",
        "            \"en_ids\": batch_en_ids,\n",
        "        }\n",
        "        return batch\n",
        "\n",
        "    return collate_fn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa63cbf2-0f31-4917-b11f-5d1d38cc458b",
      "metadata": {
        "id": "fa63cbf2-0f31-4917-b11f-5d1d38cc458b"
      },
      "outputs": [],
      "source": [
        "# function to get the data loader\n",
        "def get_data_loader(dataset, batch_size, shuffle=False):\n",
        "    collate_fn = get_collate_fn()\n",
        "    data_loader = torch.utils.data.DataLoader(\n",
        "        dataset=dataset,\n",
        "        batch_size=batch_size,\n",
        "        collate_fn=collate_fn,\n",
        "        shuffle=shuffle,\n",
        "    )\n",
        "    return data_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19625ef4-b820-4c64-ae9d-7c1986633071",
      "metadata": {
        "id": "19625ef4-b820-4c64-ae9d-7c1986633071"
      },
      "outputs": [],
      "source": [
        "# create data loaders, note: larger batch size needs more GPU power\n",
        "batch_size = 32\n",
        "\n",
        "train_data_loader = get_data_loader(train_data, batch_size, shuffle=True)\n",
        "eval_data_loader = get_data_loader(eval_data, batch_size)\n",
        "test_data_loader = get_data_loader(test_data, batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63dc6c5a-51d8-47ab-93bc-6f12943fdb62",
      "metadata": {
        "id": "63dc6c5a-51d8-47ab-93bc-6f12943fdb62"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e93e417-931e-4719-9937-a3d4be58b6e7",
      "metadata": {
        "id": "4e93e417-931e-4719-9937-a3d4be58b6e7"
      },
      "source": [
        "## Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98915382-644f-4dd1-933a-eb4d65a7dde3",
      "metadata": {
        "id": "98915382-644f-4dd1-933a-eb4d65a7dde3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "a5891167-c349-45bd-ba70-d276a38771b5",
      "metadata": {
        "id": "a5891167-c349-45bd-ba70-d276a38771b5"
      },
      "source": [
        "## Decoder"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08b91566-7a53-4b4b-98a8-aba5a2f7f9f0",
      "metadata": {
        "id": "08b91566-7a53-4b4b-98a8-aba5a2f7f9f0"
      },
      "source": [
        "## Seq2Seq"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}