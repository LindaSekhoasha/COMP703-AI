{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c0a61b90-9318-495e-a055-6450e45c2239",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\linda\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\linda\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imports\n",
    "import string\n",
    "import torch\n",
    "import pandas as pd\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "import torchtext\n",
    "from torchtext.vocab import Vocab, build_vocab_from_iterator\n",
    "from collections import Counter\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "308ad95c-3b68-4f6c-a4bf-005c1c07edab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zu</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lomkhakha kufanele uthuthukiswe, lawa amazwi k...</td>\n",
       "      <td>This sector needs to be developed,  These are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yonke imibuzo: Ucingo: 031- 311 3154 (Shaks Ra...</td>\n",
       "      <td>All questions: Phone: 031- 311 3154 (Shaks Ram...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Axhumanisa umphakathi noMkhandlu ngoba abika k...</td>\n",
       "      <td>They connect the community with the Council be...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  zu  \\\n",
       "0  Lomkhakha kufanele uthuthukiswe, lawa amazwi k...   \n",
       "1  Yonke imibuzo: Ucingo: 031- 311 3154 (Shaks Ra...   \n",
       "2  Axhumanisa umphakathi noMkhandlu ngoba abika k...   \n",
       "\n",
       "                                                  en  \n",
       "0  This sector needs to be developed,  These are ...  \n",
       "1  All questions: Phone: 031- 311 3154 (Shaks Ram...  \n",
       "2  They connect the community with the Council be...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load training dataset\n",
    "train_df = pd.read_csv(r\"../Dataset/zu-en.training.csv\")\n",
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f988f661-4c83-445e-a150-d089c50ed285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zu</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ikomidi elihlelela imidlalo ye-2013 Orange Afr...</td>\n",
       "      <td>The 2013 Orange Africa Cup of Nations (known a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Futhi ipolitiki akuwona umdlalo wabantu abanga...</td>\n",
       "      <td>And politics is not a game for  immature people.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ikhasi lethu lakwa e-Careers likubeka ngokucac...</td>\n",
       "      <td>Our e-Careers page makes it clear that if you ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  zu  \\\n",
       "0  Ikomidi elihlelela imidlalo ye-2013 Orange Afr...   \n",
       "1  Futhi ipolitiki akuwona umdlalo wabantu abanga...   \n",
       "2  Ikhasi lethu lakwa e-Careers likubeka ngokucac...   \n",
       "\n",
       "                                                  en  \n",
       "0  The 2013 Orange Africa Cup of Nations (known a...  \n",
       "1   And politics is not a game for  immature people.  \n",
       "2  Our e-Careers page makes it clear that if you ...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load evaluation dataset\n",
    "eval_df = pd.read_csv(r\"../Dataset/zu-en.eval.csv\")\n",
    "eval_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e9219e94-4c0e-47e9-a0b9-78e1219191ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zu</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NONDUDUZO NGCONGO SEKUVELILE ukuthi ezokuvakas...</td>\n",
       "      <td>NONDUDUZO NGCONGO It has come to light that to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Umkhankaso uzobe usezindaweni zokubhukuda ezis...</td>\n",
       "      <td>The campaign will be at the swimming pools in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SinguMasipala siyakuqonda ukukhala kwabantu ka...</td>\n",
       "      <td>As a Municipality we understand the cries of t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  zu  \\\n",
       "0  NONDUDUZO NGCONGO SEKUVELILE ukuthi ezokuvakas...   \n",
       "1  Umkhankaso uzobe usezindaweni zokubhukuda ezis...   \n",
       "2  SinguMasipala siyakuqonda ukukhala kwabantu ka...   \n",
       "\n",
       "                                                  en  \n",
       "0  NONDUDUZO NGCONGO It has come to light that to...  \n",
       "1  The campaign will be at the swimming pools in ...  \n",
       "2  As a Municipality we understand the cries of t...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load test dataset\n",
    "test_df = pd.read_csv(r\"../Dataset/zu-en.test.csv\")\n",
    "test_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "112e5d2b-00ec-4a07-b5fe-a34bec762572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'zu': Value(dtype='string', id=None), 'en': Value(dtype='string', id=None)}\n",
      "{'zu': Value(dtype='string', id=None), 'en': Value(dtype='string', id=None)}\n",
      "{'zu': Value(dtype='string', id=None), 'en': Value(dtype='string', id=None)}\n"
     ]
    }
   ],
   "source": [
    "# convert panda dataframes to HuggingFace datasets for easy data manipulation\n",
    "train_data = Dataset.from_pandas(train_df)\n",
    "eval_data = Dataset.from_pandas(eval_df)\n",
    "test_data = Dataset.from_pandas(test_df)\n",
    "\n",
    "# show features to work with\n",
    "print(f\"{train_data.features}\\n{eval_data.features}\\n{test_data.features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e4732dcc-d2c6-424b-b0d4-33819ff004cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # tokenize function\n",
    "# def tokenize(src_data, column):\n",
    "#   data_copy = src_data.copy()\n",
    "#   for index,row in data_copy.iterrows():\n",
    "#     col_text = row[column]\n",
    "#     col_text_without_punctuation = ''.join([char for char in col_text if char not in string.punctuation])\n",
    "#     token = word_tokenize(col_text_without_punctuation)\n",
    "#     data_copy.at[index, column] = token\n",
    "#   return data_copy\n",
    "\n",
    "# # tokenize zu\n",
    "# df_copy = tokenize(df, 'zu')\n",
    "# # zulu_tokenized = df_copy['zu']\n",
    "\n",
    "# # tokenize en\n",
    "# df_copy = tokenize(df_copy, 'en')\n",
    "# # english_tokenized = df_copy['en']\n",
    "\n",
    "# df_copy.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1f9359df-3d56-4191-88eb-fe38eaea998a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to tokenize a row (example) in dataset using .map function\n",
    "def tokenize_example(example, max_length, lower, sos_token, eos_token):\n",
    "    zu_tokens = word_tokenize(example[\"zu\"])[:max_length]\n",
    "    en_tokens = word_tokenize(example[\"en\"])[:max_length]\n",
    "    if lower:\n",
    "        zu_tokens = [token.lower() for token in zu_tokens]\n",
    "        en_tokens = [token.lower() for token in en_tokens]\n",
    "    zu_tokens = [sos_token] + zu_tokens + [eos_token]\n",
    "    en_tokens = [sos_token] + en_tokens + [eos_token]\n",
    "    return {\"zu_tokens\": zu_tokens, \"en_tokens\": en_tokens}\n",
    "\n",
    "    \n",
    "# maybe try with spacy (treating zulu as english and tokenize both with en_nlp?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2308110a-30fa-421e-b415-23d3e24d9766",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|████████████████████████████████████████████████████████████████| 4960/4960 [00:01<00:00, 4141.05 examples/s]\n",
      "Map: 100%|██████████████████████████████████████████████████████████████████| 498/498 [00:00<00:00, 3761.39 examples/s]\n",
      "Map: 100%|██████████████████████████████████████████████████████████████████| 487/487 [00:00<00:00, 3986.90 examples/s]\n"
     ]
    }
   ],
   "source": [
    "max_length = 500\n",
    "lower = True\n",
    "sos_token = \"<sos>\"\n",
    "eos_token = \"<eos>\"\n",
    "\n",
    "fn_kwargs = {\n",
    "    \"max_length\": max_length,\n",
    "    \"lower\": lower,\n",
    "    \"sos_token\": sos_token,\n",
    "    \"eos_token\": eos_token,\n",
    "}\n",
    "\n",
    "train_data = train_data.map(tokenize_example, fn_kwargs=fn_kwargs)\n",
    "eval_data = eval_data.map(tokenize_example, fn_kwargs=fn_kwargs)\n",
    "test_data = test_data.map(tokenize_example, fn_kwargs=fn_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5013862d-635a-4d6d-a77c-3064ab0dd6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4960lines [00:00, 259712.47lines/s]\n",
      "4960lines [00:00, 206130.77lines/s]\n"
     ]
    }
   ],
   "source": [
    "# build vocabulary\n",
    "min_freq = 1    # maybe change to 2\n",
    "zu_counter = Counter()\n",
    "en_counter = Counter()\n",
    "\n",
    "for tokens in train_data[\"zu_tokens\"]:\n",
    "    zu_counter.update(tokens)\n",
    "\n",
    "for tokens in train_data[\"en_tokens\"]:\n",
    "    en_counter.update(tokens)\n",
    "\n",
    "zu_vocab = build_vocab_from_iterator(\n",
    "    train_data[\"zu_tokens\"],\n",
    ")\n",
    "\n",
    "en_vocab = build_vocab_from_iterator(\n",
    "    train_data[\"en_tokens\"],\n",
    ")\n",
    "\n",
    "# apply min_freq\n",
    "zu_vocab = Vocab(zu_counter, min_freq=min_freq)\n",
    "en_vocab = Vocab(en_counter, min_freq=min_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "62e0face-b79f-468f-8260-a538e6bf2a90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', '<pad>', '.', '<eos>', '<sos>', ',', 'ukuthi', ':', '(', ')']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show items in vocab, torchtext adds unk and pad tokens\n",
    "# unk is for words in eval and test but not in train\n",
    "zu_vocab.itos[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bfcf2b0b-fb71-4a52-b268-48190d2ff6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert tokens in vocab to indices\n",
    "def numericalize_example(example, zu_vocab , en_vocab):\n",
    "    zu_ids = [zu_vocab.stoi[token] for token in example[\"zu_tokens\"]]\n",
    "    en_ids = [en_vocab.stoi[token] for token in example[\"en_tokens\"]]\n",
    "    return {\"zu_ids\": zu_ids, \"en_ids\": en_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e0443941-4229-4a97-a478-5beae5c8732f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|████████████████████████████████████████████████████████████████| 4960/4960 [00:00<00:00, 6394.89 examples/s]\n",
      "Map: 100%|██████████████████████████████████████████████████████████████████| 498/498 [00:00<00:00, 5725.98 examples/s]\n",
      "Map: 100%|██████████████████████████████████████████████████████████████████| 487/487 [00:00<00:00, 6191.18 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# use .map function to iteratively use the numericalize_example function\n",
    "fn_kwargs = {\"zu_vocab\": zu_vocab, \"en_vocab\": en_vocab}\n",
    "\n",
    "train_data = train_data.map(numericalize_example, fn_kwargs=fn_kwargs)\n",
    "eval_data = eval_data.map(numericalize_example, fn_kwargs=fn_kwargs)\n",
    "test_data = test_data.map(numericalize_example, fn_kwargs=fn_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0bb1d324-6b62-430c-811b-f5dd7ba0a259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'zu': 'Lomkhakha kufanele uthuthukiswe, lawa amazwi kaSomlomo, uLogie Naidoo ekhuluma kwinkomfa nombukiso wobuciko ebuse Durban ICC ngesonto elidlule.',\n",
       " 'en': 'This sector needs to be developed,  These are the words of Speaker, Logie Naidoo, from a conference and art exhibition held at the Durban ICC last week.',\n",
       " 'zu_tokens': ['<sos>',\n",
       "  'lomkhakha',\n",
       "  'kufanele',\n",
       "  'uthuthukiswe',\n",
       "  ',',\n",
       "  'lawa',\n",
       "  'amazwi',\n",
       "  'kasomlomo',\n",
       "  ',',\n",
       "  'ulogie',\n",
       "  'naidoo',\n",
       "  'ekhuluma',\n",
       "  'kwinkomfa',\n",
       "  'nombukiso',\n",
       "  'wobuciko',\n",
       "  'ebuse',\n",
       "  'durban',\n",
       "  'icc',\n",
       "  'ngesonto',\n",
       "  'elidlule',\n",
       "  '.',\n",
       "  '<eos>'],\n",
       " 'en_tokens': ['<sos>',\n",
       "  'this',\n",
       "  'sector',\n",
       "  'needs',\n",
       "  'to',\n",
       "  'be',\n",
       "  'developed',\n",
       "  ',',\n",
       "  'these',\n",
       "  'are',\n",
       "  'the',\n",
       "  'words',\n",
       "  'of',\n",
       "  'speaker',\n",
       "  ',',\n",
       "  'logie',\n",
       "  'naidoo',\n",
       "  ',',\n",
       "  'from',\n",
       "  'a',\n",
       "  'conference',\n",
       "  'and',\n",
       "  'art',\n",
       "  'exhibition',\n",
       "  'held',\n",
       "  'at',\n",
       "  'the',\n",
       "  'durban',\n",
       "  'icc',\n",
       "  'last',\n",
       "  'week',\n",
       "  '.',\n",
       "  '<eos>'],\n",
       " 'zu_ids': [4,\n",
       "  5501,\n",
       "  43,\n",
       "  20930,\n",
       "  5,\n",
       "  1898,\n",
       "  2178,\n",
       "  5114,\n",
       "  5,\n",
       "  2064,\n",
       "  812,\n",
       "  469,\n",
       "  14252,\n",
       "  5926,\n",
       "  21606,\n",
       "  9891,\n",
       "  97,\n",
       "  1113,\n",
       "  484,\n",
       "  4581,\n",
       "  2,\n",
       "  3],\n",
       " 'en_ids': [5,\n",
       "  14,\n",
       "  340,\n",
       "  256,\n",
       "  6,\n",
       "  16,\n",
       "  835,\n",
       "  7,\n",
       "  46,\n",
       "  18,\n",
       "  2,\n",
       "  1421,\n",
       "  8,\n",
       "  736,\n",
       "  7,\n",
       "  1503,\n",
       "  769,\n",
       "  7,\n",
       "  36,\n",
       "  12,\n",
       "  192,\n",
       "  9,\n",
       "  1315,\n",
       "  381,\n",
       "  105,\n",
       "  21,\n",
       "  2,\n",
       "  39,\n",
       "  975,\n",
       "  167,\n",
       "  396,\n",
       "  3,\n",
       "  4]}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show new features in an example (zu_ids and en_ids)\n",
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5852138f-ce21-45bc-99c9-ad7346e295ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert indices to PyTorch tensors for use with PyTorch\n",
    "data_type = \"torch\"\n",
    "format_columns = [\"zu_ids\", \"en_ids\"]\n",
    "\n",
    "train_data = train_data.with_format(\n",
    "    type=data_type,\n",
    "    columns=format_columns,\n",
    "    output_all_columns=True,\n",
    ")\n",
    "\n",
    "eval_data = eval_data.with_format(\n",
    "    type=data_type,\n",
    "    columns=format_columns,\n",
    "    output_all_columns=True,\n",
    ")\n",
    "\n",
    "test_data = test_data.with_format(\n",
    "    type=data_type,\n",
    "    columns=format_columns,\n",
    "    output_all_columns=True,\n",
    ")\n",
    "\n",
    "# show new type of indices\n",
    "type(train_data[0][\"en_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d536368d-caa3-488b-b1c8-0e002a920974",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
