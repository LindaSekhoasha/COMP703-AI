{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0a61b90-9318-495e-a055-6450e45c2239",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\linda\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\linda\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imports\n",
    "import string\n",
    "import torch\n",
    "import pandas as pd\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "# import torchtext\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "308ad95c-3b68-4f6c-a4bf-005c1c07edab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zu</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lomkhakha kufanele uthuthukiswe, lawa amazwi k...</td>\n",
       "      <td>This sector needs to be developed,  These are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yonke imibuzo: Ucingo: 031- 311 3154 (Shaks Ra...</td>\n",
       "      <td>All questions: Phone: 031- 311 3154 (Shaks Ram...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Axhumanisa umphakathi noMkhandlu ngoba abika k...</td>\n",
       "      <td>They connect the community with the Council be...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  zu  \\\n",
       "0  Lomkhakha kufanele uthuthukiswe, lawa amazwi k...   \n",
       "1  Yonke imibuzo: Ucingo: 031- 311 3154 (Shaks Ra...   \n",
       "2  Axhumanisa umphakathi noMkhandlu ngoba abika k...   \n",
       "\n",
       "                                                  en  \n",
       "0  This sector needs to be developed,  These are ...  \n",
       "1  All questions: Phone: 031- 311 3154 (Shaks Ram...  \n",
       "2  They connect the community with the Council be...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load training dataset\n",
    "train_df = pd.read_csv(r\"../Dataset/zu-en.training.csv\")\n",
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f988f661-4c83-445e-a150-d089c50ed285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zu</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ikomidi elihlelela imidlalo ye-2013 Orange Afr...</td>\n",
       "      <td>The 2013 Orange Africa Cup of Nations (known a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Futhi ipolitiki akuwona umdlalo wabantu abanga...</td>\n",
       "      <td>And politics is not a game for  immature people.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ikhasi lethu lakwa e-Careers likubeka ngokucac...</td>\n",
       "      <td>Our e-Careers page makes it clear that if you ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  zu  \\\n",
       "0  Ikomidi elihlelela imidlalo ye-2013 Orange Afr...   \n",
       "1  Futhi ipolitiki akuwona umdlalo wabantu abanga...   \n",
       "2  Ikhasi lethu lakwa e-Careers likubeka ngokucac...   \n",
       "\n",
       "                                                  en  \n",
       "0  The 2013 Orange Africa Cup of Nations (known a...  \n",
       "1   And politics is not a game for  immature people.  \n",
       "2  Our e-Careers page makes it clear that if you ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load evaluation dataset\n",
    "eval_df = pd.read_csv(r\"../Dataset/zu-en.eval.csv\")\n",
    "eval_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9219e94-4c0e-47e9-a0b9-78e1219191ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zu</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NONDUDUZO NGCONGO SEKUVELILE ukuthi ezokuvakas...</td>\n",
       "      <td>NONDUDUZO NGCONGO It has come to light that to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Umkhankaso uzobe usezindaweni zokubhukuda ezis...</td>\n",
       "      <td>The campaign will be at the swimming pools in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SinguMasipala siyakuqonda ukukhala kwabantu ka...</td>\n",
       "      <td>As a Municipality we understand the cries of t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  zu  \\\n",
       "0  NONDUDUZO NGCONGO SEKUVELILE ukuthi ezokuvakas...   \n",
       "1  Umkhankaso uzobe usezindaweni zokubhukuda ezis...   \n",
       "2  SinguMasipala siyakuqonda ukukhala kwabantu ka...   \n",
       "\n",
       "                                                  en  \n",
       "0  NONDUDUZO NGCONGO It has come to light that to...  \n",
       "1  The campaign will be at the swimming pools in ...  \n",
       "2  As a Municipality we understand the cries of t...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load test dataset\n",
    "test_df = pd.read_csv(r\"../Dataset/zu-en.test.csv\")\n",
    "test_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "112e5d2b-00ec-4a07-b5fe-a34bec762572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'zu': Value(dtype='string', id=None), 'en': Value(dtype='string', id=None)}\n",
      "{'zu': Value(dtype='string', id=None), 'en': Value(dtype='string', id=None)}\n",
      "{'zu': Value(dtype='string', id=None), 'en': Value(dtype='string', id=None)}\n"
     ]
    }
   ],
   "source": [
    "# convert panda dataframes to HuggingFace datasets for easy data manipulation\n",
    "train_data = Dataset.from_pandas(train_df)\n",
    "eval_data = Dataset.from_pandas(eval_df)\n",
    "test_data = Dataset.from_pandas(test_df)\n",
    "\n",
    "# show features to work with\n",
    "print(f\"{train_data.features}\\n{eval_data.features}\\n{test_data.features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4732dcc-d2c6-424b-b0d4-33819ff004cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # tokenize function\n",
    "# def tokenize(src_data, column):\n",
    "#   data_copy = src_data.copy()\n",
    "#   for index,row in data_copy.iterrows():\n",
    "#     col_text = row[column]\n",
    "#     col_text_without_punctuation = ''.join([char for char in col_text if char not in string.punctuation])\n",
    "#     token = word_tokenize(col_text_without_punctuation)\n",
    "#     data_copy.at[index, column] = token\n",
    "#   return data_copy\n",
    "\n",
    "# # tokenize zu\n",
    "# df_copy = tokenize(df, 'zu')\n",
    "# # zulu_tokenized = df_copy['zu']\n",
    "\n",
    "# # tokenize en\n",
    "# df_copy = tokenize(df_copy, 'en')\n",
    "# # english_tokenized = df_copy['en']\n",
    "\n",
    "# df_copy.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f9359df-3d56-4191-88eb-fe38eaea998a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to tokenize a row (example) in dataset using .map function\n",
    "def tokenize_example(example, max_length, lower, sos_token, eos_token):\n",
    "    zu_tokens = word_tokenize(example[\"zu\"])[:max_length]\n",
    "    en_tokens = word_tokenize(example[\"en\"])[:max_length]\n",
    "    if lower:\n",
    "        zu_tokens = [token.lower() for token in zu_tokens]\n",
    "        en_tokens = [token.lower() for token in en_tokens]\n",
    "    zu_tokens = [sos_token] + zu_tokens + [eos_token]\n",
    "    en_tokens = [sos_token] + en_tokens + [eos_token]\n",
    "    return {\"zu_tokens\": zu_tokens, \"en_tokens\": en_tokens}\n",
    "\n",
    "    \n",
    "# maybe try with spacy (treating zulu as english and tokenize both with en_nlp?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2308110a-30fa-421e-b415-23d3e24d9766",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|████████████████████████████████████████████████████████████████| 4960/4960 [00:01<00:00, 4243.81 examples/s]\n",
      "Map: 100%|██████████████████████████████████████████████████████████████████| 498/498 [00:00<00:00, 3987.97 examples/s]\n",
      "Map: 100%|██████████████████████████████████████████████████████████████████| 487/487 [00:00<00:00, 4638.16 examples/s]\n"
     ]
    }
   ],
   "source": [
    "max_length = 500\n",
    "lower = True\n",
    "sos_token = \"<sos>\"\n",
    "eos_token = \"<eos>\"\n",
    "\n",
    "fn_kwargs = {\n",
    "    \"max_length\": max_length,\n",
    "    \"lower\": lower,\n",
    "    \"sos_token\": sos_token,\n",
    "    \"eos_token\": eos_token,\n",
    "}\n",
    "\n",
    "train_data = train_data.map(tokenize_example, fn_kwargs=fn_kwargs)\n",
    "eval_data = eval_data.map(tokenize_example, fn_kwargs=fn_kwargs)\n",
    "test_data = test_data.map(tokenize_example, fn_kwargs=fn_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5013862d-635a-4d6d-a77c-3064ab0dd6da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
